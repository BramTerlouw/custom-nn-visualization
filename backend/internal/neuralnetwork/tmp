// type Network struct {
// 	inputSize, hiddenSize, outputSize int
// 	WeightsHidden, WeightsOutput      *mat.Dense
// 	learningRate                      float64
// }

// func NewNetwork(inputSize, hiddenSize, outputSize int, learningRate float64) *Network {

// 	// Initialize network
// 	n := &Network{
// 		inputSize:    inputSize,
// 		hiddenSize:   hiddenSize,
// 		outputSize:   outputSize,
// 		learningRate: learningRate,
// 	}

// 	// Initialize weights with random values
// 	n.WeightsHidden = mat.NewDense(n.hiddenSize, n.inputSize, randomArray(n.inputSize*n.hiddenSize, float64(n.inputSize)))
// 	n.WeightsOutput = mat.NewDense(n.outputSize, n.hiddenSize, randomArray(n.hiddenSize*n.outputSize, float64(n.hiddenSize)))

// 	return n
// }

// func (net *Network) Train(inputData []float64, targetData []float64) {
// 	// === FORWARD PROPAGATION ===

// 	// Step 1: Convert input data slice into a column matrix
// 	inputs := mat.NewDense(len(inputData), 1, inputData)

// 	// Step 2: Calculate input to hidden layer
// 	hiddenInputs := Matrix_multiply(net.WeightsHidden, inputs)

// 	// Step 3: Apply activation function (sigmoid) to hidden layer inputs
// 	hiddenOutputs := Apply_fn(Sigmoid, hiddenInputs)

// 	// Step 4: Calculate input to output layer using weights from hidden to output
// 	finalInputs := Matrix_multiply(net.WeightsOutput, hiddenOutputs)

// 	// Step 5: Apply activation function (sigmoid) to get the final output of the network
// 	finalOutputs := Apply_fn(Sigmoid, finalInputs)

// 	// === ERROR CALCULATION ===

// 	// Step 6: Convert target data slice into a column matrix
// 	targets := mat.NewDense(len(targetData), 1, targetData)

// 	// Step 7: Calculate output layer error (target - actual output)
// 	outputErrors := Subtract_matrix(targets, finalOutputs)

// 	// Step 8: Calculate hidden layer error by propagating output error back through the weights
// 	hiddenErrors := Matrix_multiply(net.WeightsOutput.T(), outputErrors)

// 	// === BACKPROPAGATION & WEIGHT UPDATE ===

// 	// Step 9: Update weights between hidden and output layers
// 	// Add to existing weights of output layer
// 	net.WeightsOutput = Add_matrix(net.WeightsOutput,

// 		// Scale by the learning rate
// 		Scale_matrix(net.learningRate,

// 			// Multiply sigmoid prime with output layer outputs transposed => dW = δ * hiddenOutputsᵀ
// 			Matrix_multiply(

// 				// Multiply output error by derivative of activation (sigmoid prime) => δ = error * sigmoid'
// 				Element_multiply(outputErrors, SigmoidPrime(finalOutputs)),
// 				hiddenOutputs.T(),
// 			),
// 		)).(*mat.Dense)

// 	// Step 10: Update weights between input and hidden layers
// 	// Add to existing weights of hidden layer
// 	net.WeightsHidden = Add_matrix(net.WeightsHidden,

// 		// Scale by the learning rate
// 		Scale_matrix(net.learningRate,

// 			// Multiply sigmoid prime with input layer inputs transposed => dW = δ * hiddenOutputsᵀ
// 			Matrix_multiply(

// 				// Multiply hidden error by derivative of activation (sigmoid prime) => δ = error * sigmoid'
// 				Element_multiply(hiddenErrors, SigmoidPrime(hiddenOutputs)), // δ = error * sigmoid'
// 				inputs.T(),
// 			),
// 		)).(*mat.Dense)
// }

// func (net *Network) Forward(inputData []float64, targetData []float64) mat.Matrix {
// 	// forward propagation
// 	inputs := mat.NewDense(len(inputData), 1, inputData)
// 	hiddenInputs := Matrix_multiply(net.WeightsHidden, inputs)
// 	hiddenOutputs := Apply_fn(Sigmoid, hiddenInputs)
// 	finalInputs := Matrix_multiply(net.WeightsOutput, hiddenOutputs)
// 	finalOutputs := Apply_fn(Sigmoid, finalInputs)
// 	return finalOutputs
// }
